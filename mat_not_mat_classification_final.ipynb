{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "# imports\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mne.decoding import LinearModel\n",
    "from mne.decoding import get_coef\n",
    "from mne.time_frequency import psd_multitaper\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to data \n",
    "path = '/Users/ilamiheev/Downloads/eeg_data'\n",
    "# create folders for results\n",
    "path_res = '/Users/ilamiheev/Downloads/results_ihna'\n",
    "path_subj = os.path.join(path_res, 'subjects_classification')\n",
    "path_subj_topo = os.path.join(path_subj, 'subjects_topo')\n",
    "path_unite_subj = os.path.join(path_res, 'unite_subjects')\n",
    "path_unite_topo =  os.path.join(path_unite_subj, 'unite_topo')\n",
    "path_group = os.path.join(path_res, 'group_classification')\n",
    "path_group_topo =  os.path.join(path_group, 'group_topo')\n",
    "for pathn in [path_res,path_subj,path_subj_topo,path_unite_subj,path_unite_topo,path_group,path_group_topo]:\n",
    "    os.makedirs(pathn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg parameters and subjects indexes\n",
    "files = [f for f in sorted(os.listdir(path))]\n",
    "_ = files.pop(0)\n",
    "indexes = []\n",
    "for i,j in enumerate(files):\n",
    "    indexes.append(re.search('(.+?)_', j).group(1))\n",
    "chan_drop = ['E8','E14','E21','E25','E43','E48','E49','E56','E57','E63','E64','E65','E68','E69','E73','E74','E81'\n",
    "             ,'E82','E88','E89','E90','E94','E95','E99','E100','E107','E113','E119','E120','E125','E126','E127'\n",
    "             ,'E128','Status']\n",
    "montage = mne.channels.make_standard_montage('GSN-HydroCel-128')\n",
    "events_list = [241,242,244]\n",
    "fr_bands = {   \"theta1\":  [4,6],\n",
    "               \"theta2\":  [6,8],\n",
    "               \"alpha1\": [8,10],\n",
    "               \"alpha2\": [10,12],\n",
    "               \"beta1\":  [12,16],\n",
    "               \"beta2\":  [16,20],\n",
    "               \"beta3\":  [20,24] }\n",
    "dict_cls = { \"241/244\": [0,2],\n",
    "             \"242/244\": [1,2],\n",
    "             \"241/242\": [0,1] }\n",
    "mat = ['311','312','314','315','316','317','326','327','328','330','334','335']  \n",
    "not_mat = [x for x in indexes if x not in mat]\n",
    "index_mat, index_not_mat = [indexes.index(i) for i in mat], [indexes.index(i) for i in not_mat] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate relative power \n",
    "def eeg_power_band(epochs_list):\n",
    "    fin_table, fin_feat = [], []\n",
    "    for beta in range(len(epochs_list)):\n",
    "        psds, freqs = psd_multitaper(epochs_list[beta])\n",
    "        psds_table = np.mean(psds, axis=0)\n",
    "        psds /= psds.sum(axis=-1)[..., None]\n",
    "        psds_table /= psds_table.sum(axis=-1)[..., None]\n",
    "        psd_table_list, psd_features_list = [], []\n",
    "        for fmin, fmax in fr_bands.values():\n",
    "            freq_mask = (fmin < freqs) & (freqs < fmax)\n",
    "            data_table, data_feat = psds_table[..., freq_mask].mean(axis=-1), psds[..., freq_mask].mean(axis=-1)\n",
    "            psd_features_list.append(data_feat)\n",
    "            psd_table_list.append(data_table)\n",
    "        fin_table.append(psd_table_list)\n",
    "        fin_feat.append(psd_features_list)\n",
    "    return fin_feat, fin_table\n",
    "# logistic regression with l2 penalty and CV\n",
    "def predict(x_train, x_test, y_train, y_test):\n",
    "    results = np.zeros((1,4))\n",
    "    model = make_pipeline( StandardScaler(),                  \n",
    "                               LinearModel(LogisticRegressionCV(\n",
    "                               Cs=list(np.power(10.0, np.arange(-10, 10))),\n",
    "                               penalty='l2',\n",
    "                               scoring='roc_auc',\n",
    "                                                                                                                                                                                  random_state=0,\n",
    "                               max_iter=10000,\n",
    "                               fit_intercept=True,\n",
    "                               solver='newton-cg',\n",
    "                               tol=10 \n",
    "                                                                       ))) \n",
    "    model.fit(x_train, y_train)\n",
    "    y_predict = model.predict(x_test)\n",
    "    score = model.score(x_test,y_test)\n",
    "    cm=confusion_matrix(y_test,y_predict)\n",
    "    TN,TP,FN,FP = cm[1,1],cm[0,0],cm[1,0],cm[0,1]\n",
    "    results[0,0], results[0,1] = accuracy_score(y_test,y_predict), score\n",
    "    results[0,2], results[0,3] = TP/float(TP+FN), TN/float(TN+FP)\n",
    "    return results, model\n",
    "# plot topomap for each freq band\n",
    "def plot_topo(ar):\n",
    "    vmin = np.amin(ar)\n",
    "    vmax = np.amax(ar)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=7, figsize=(30, 20)) \n",
    "    for name, pos, plot_name, ind in zip(('patterns_', 'filters_'),(0.8,0.5),\n",
    "                                         ('Patterns','Filters'),(0,1)):\n",
    "        for i,key in enumerate(list(fr_bands.keys())):\n",
    "            a = mne.viz.plot_topomap(ar[ind,i,:],info,vmin=vmin,vmax=vmax, axes=axes[ind,i], \n",
    "                                 show = False)\n",
    "            axes[ind,i].set(title='{}-{} Hz'.format(*fr_bands[key]))\n",
    "            mne.viz.tight_layout() \n",
    "        plt.figtext(0.5,pos,'{}'.format(plot_name), va=\"center\", ha=\"center\", size=24, fontweight = 'semibold',)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features\n",
    "subj_list_table, subj_list_features = [], []\n",
    "for file_name in files:\n",
    "    paths = glob.glob(path + '/{0}/Reals/*.edf'.format(file_name))\n",
    "    epochs_list = []\n",
    "    for event_ind in events_list:\n",
    "        j = 0\n",
    "        for i in [x for x in paths if '{0}'.format(event_ind) in x]: \n",
    "            event_id = dict(a=event_ind)\n",
    "            raw = mne.io.read_raw_edf(i)\n",
    "            if  len(raw.times)//500 < 10:\n",
    "                continue  \n",
    "            new_events = mne.make_fixed_length_events(raw, id=event_ind, start=5, duration=2, overlap=1)\n",
    "            if j==1:\n",
    "                epochs = mne.concatenate_epochs([mne.Epochs(raw, new_events, event_id = event_id, tmin=0, \n",
    "                                                            tmax=2, baseline=None, flat=dict(eeg=1e-20), \n",
    "                                                            preload=True), epochs])\n",
    "            else:\n",
    "                epochs = mne.Epochs(raw, new_events, event_id = event_id , tmin=0, tmax=2, baseline=None, \n",
    "                                    flat=dict(eeg=1e-20), preload=True)\n",
    "                j+=1\n",
    "        epochs_list.append(epochs.copy())\n",
    "    for teta in range(len(epochs_list)):\n",
    "            new_names = dict(\n",
    "                    (ch_name,\n",
    "                     ch_name.replace('-', '').replace('Chan ', 'E').replace('CAR', '').replace('EEG ', '')\n",
    "                     .replace('CA', '').replace(' ', ''))\n",
    "                     for ch_name in epochs_list[teta].ch_names)\n",
    "            epochs_list[teta].rename_channels(new_names)\n",
    "            epochs_list[teta].set_montage(montage)\n",
    "            epochs_list[teta].drop_channels(chan_drop)\n",
    "    feat_list, tabl_list = eeg_power_band(epochs_list)\n",
    "    subj_list_table.append(tabl_list)\n",
    "    subj_list_features.append(feat_list)\n",
    "chan1 = epochs_list[0].ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about chan positions\n",
    "info = epochs_list[1].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write relative powers to table\n",
    "# write new powers to table_1\n",
    "df1,df2 = {}, {}\n",
    "k, l = 0, 0\n",
    "for i in range(len(subj_list_table[0])):\n",
    "    for j in range(len(subj_list_table[0][0])):\n",
    "        df1[k] = np.array(subj_list_table)[:,i,j,:]\n",
    "        k += 1\n",
    "for s in list(df1.keys()):      \n",
    "    df2[s] = pd.DataFrame(columns=chan1, index=indexes)\n",
    "    for ind_num,ind_name in enumerate(indexes):\n",
    "        df2[s].loc['{}'.format(ind_name)] = pd.Series(df1[s][ind_num,:], chan1)\n",
    "writer = pd.ExcelWriter(os.path.join(path_res, 'subjects_relative_power.xlsx'), engine='xlsxwriter')\n",
    "for ind in events_list:\n",
    "    for band_name in list(fr_bands.keys()):\n",
    "        df2[l].to_excel(writer, sheet_name='{},({},{})'.format(ind, *fr_bands[band_name]))\n",
    "        l += 1\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification for each subject in both groups\n",
    "# add new pooling layer\n",
    "results, coefs = np.zeros((len(indexes),12)), np.zeros((len(indexes),len(dict_cls),2,len(fr_bands),len(chan1))) \n",
    "for subj in range(len(indexes)):\n",
    "    k = 4             \n",
    "    for i, key in enumerate(list(dict_cls.keys())):\n",
    "        ind = dict_cls[key]\n",
    "        A, B = np.stack(subj_list_features[subj][ind[0]],axis=1), np.stack(subj_list_features[subj][ind[1]],axis=1)\n",
    "        y = ['0']*A.shape[0] + ['1']*B.shape[0] \n",
    "        x = np.concatenate((A,B),axis=0)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x.reshape(x.shape[0],-1), y, test_size=0.3)\n",
    "        results[subj,k-4:k], model = predict(x_train, x_test, y_train, y_test)\n",
    "        for name, j in zip(['patterns_', 'filters_'],[0,1]):\n",
    "            coef = get_coef(model, name, inverse_transform=True)\n",
    "            coefs[subj,i,j,...] = coef.reshape(len(fr_bands),-1)\n",
    "        k+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate mean and var for all subjects/and for subjects in groups\n",
    "list_gr, ar_mean_var = [results,results[index_mat,...],results[index_not_mat,...]], np.zeros((3,24))\n",
    "list_names_subj, list_names_fin = [], []\n",
    "metr_name = ['accuracy','ROC/AUC','TPR','TNR']\n",
    "for i, key in enumerate(list(dict_cls.keys())):\n",
    "    ar_mean_var[i,...] = np.array(list(chain.from_iterable((a, b) for a,b in zip(list_gr[i].mean(axis=0),\n",
    "                                                                                 list_gr[i].var(axis=0)))))\n",
    "    list_names_subj.extend(['{} {}'.format(key,name) for name in metr_name])\n",
    "    list_names_fin.extend(['{} {}'.format(key,name) for name in ['{} {}'.format(i,j) for i in metr_name \n",
    "                                                                 for j in ['mean','var'] ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to table\n",
    "df_subj = pd.DataFrame(results, columns=list_names_subj, index=indexes)\n",
    "df_fin = pd.DataFrame(ar_mean_var, columns=list_names_fin, \n",
    "                       index=['all_subjects','mathematicians','not_mathematicians'])\n",
    "writer = pd.ExcelWriter(os.path.join(path_subj, 'subjects_classification_l1_final.xlsx'), engine='xlsxwriter')\n",
    "df_subj.to_excel(writer, sheet_name='all_subj')\n",
    "df_fin.to_excel(writer, sheet_name='mean_var')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot topomaps for each subject\n",
    "# add function for removing channels\n",
    "for i, subj_ind in enumerate(indexes):\n",
    "    for j, key in enumerate(list(dict_cls.keys())):\n",
    "        fig = plot_topo(coefs[i,j])\n",
    "        fig.savefig(os.path.join(path_subj_topo, 'filters_patterns_{}_{}.png'\n",
    "                                 .format(subj_ind,['241_244','242_244','241_242'][j])), format='png', dpi=600)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification using all subjects in both groups and all subjects\n",
    "results_all, coefs_all = np.zeros((3,12)), np.zeros((3,len(dict_cls),2,len(fr_bands),len(chan1))) \n",
    "for group_ind, subj_type in enumerate([[*range(len(indexes))],index_mat,index_not_mat]):\n",
    "    k = 4\n",
    "    # create new loop for prediction of target\n",
    "    for i, key in enumerate(list(dict_cls.keys())):\n",
    "        ind = dict_cls[key]\n",
    "        A = np.concatenate(([np.stack([subj_list_features[j] for j in subj_type][i][ind[0]],axis = 1) \n",
    "                            for i in range(len(subj_type))]),axis=0)\n",
    "        B = np.concatenate(([np.stack([subj_list_features[j] for j in subj_type][i][ind[1]],axis = 1) \n",
    "                            for i in range(len(subj_type))]),axis=0)\n",
    "        y = ['0']*A.shape[0] + ['1']*B.shape[0] \n",
    "        x = np.concatenate((A,B),axis=0)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x.reshape(x.shape[0],-1), y, test_size=0.3)\n",
    "        results_all[group_ind,k-4:k], model = predict(x_train, x_test, y_train, y_test)\n",
    "        for name, j in zip(['patterns_', 'filters_'],[0,1]):\n",
    "            coef = get_coef(model, name, inverse_transform=True)\n",
    "            coefs_all[group_ind,i,j,...] = coef.reshape(len(fr_bands),-1)\n",
    "        k+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to table\n",
    "datafr_groups = pd.DataFrame(results_all, columns=list_names_subj, index=['all_sibjects','mathematicians','not_mathematicians'])\n",
    "datafr_groups.to_excel(os.path.join(path_unite_subj, 'subj_in_groups_classification_l2.xlsx'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot topomaps for subjects in groups\n",
    "group_names = ['all_subjects','mathematicians','not_mathematicians']\n",
    "for i, group_ind in enumerate(group_names):\n",
    "    for j, key in enumerate(list(dict_cls.keys())):\n",
    "        fig = plot_topo(coefs_all[i,j,...])\n",
    "        fig.savefig(os.path.join(path_unite_topo, 'filters_patterns_{}_{}.png'\n",
    "                                 .format(group_ind,['241_244','242_244','241_242'][j])), format='png', dpi=600)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification mathematicians/non mathematicians\n",
    "results_group, coefs_group = np.zeros((4,4)), np.zeros((4,2,len(fr_bands),len(chan1)))\n",
    "list_A, list_B = [], []\n",
    "for ind in range(4):\n",
    "    if ind < 3:\n",
    "        A =  np.concatenate(([np.stack([subj_list_features[j] for j in index_mat][i][ind],axis = 1)\n",
    "                              for i in range(len(mat))]),axis=0)\n",
    "        list_A.append(A)\n",
    "        B =  np.concatenate(([np.stack([subj_list_features[j] for j in index_not_mat][i][ind],axis = 1)\n",
    "                              for i in range(len(not_mat))]),axis=0)\n",
    "        list_B.append(B)\n",
    "    else:\n",
    "        A, B = np.concatenate(list_A,axis=0), np.concatenate(list_B,axis=0)\n",
    "    y = ['0']*A.shape[0] + ['1']*B.shape[0] \n",
    "    x = np.concatenate((A,B),axis=0)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x.reshape(x.shape[0],-1), y, test_size=0.3)\n",
    "    results_group[ind,...], model = predict(x_train, x_test, y_train, y_test)\n",
    "    for name, i in zip(['patterns_', 'filters_'],[0,1]):\n",
    "        coef = get_coef(model, name, inverse_transform=True)\n",
    "        coefs_group[ind,i,...] = coef.reshape(len(fr_bands),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new results to table\n",
    "datafr_math_not_math = pd.DataFrame(results_group, columns=['accuracy score','roc_auc score','sensitivity(TPR)',\n",
    "                                             'specificity(TNR)'], index= ['241','242','244','all'])\n",
    "datafr_math_not_math.to_excel(os.path.join(path_group, 'group_classification_l2.xlsx'), index=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save topomaps for mat/not mat\n",
    "for i in range(4):\n",
    "    fig = plot_topo(coefs_group[i,...])\n",
    "    fig.savefig(os.path.join(path_group_topo, 'filters_patterns_mat_not_mat_{}.png'\n",
    "                             .format(['241','242','244','all'][i])), format='png', dpi=600)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}